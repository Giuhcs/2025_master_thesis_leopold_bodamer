{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:09.441048Z",
     "start_time": "2025-01-31T16:10:08.721967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "from qutip import * \n",
    "import os\n",
    "\n",
    "# Matplotlib Einstellungen gemäß den LaTeX-Caption-Formatierungen\n",
    "plt.rcParams.update({\n",
    "#    'text.usetex': True,              # Enable LaTeX for text rendering\n",
    "#    'font.family': 'serif',           # Use a serif font family\n",
    "#    'font.serif': 'Palatino',         # Set Palatino as the serif font\n",
    "#    'text.latex.preamble': r'\\usepackage{amsmath}',\n",
    "#    'font.size': 20,                   # Font size for general text\n",
    "#    'axes.titlesize': 20,              # Font size for axis titles\n",
    "#    'axes.labelsize': 20,              # Font size for axis labels\n",
    "#    'xtick.labelsize': 20,             # Font size for x-axis tick labels\n",
    "#    'ytick.labelsize': 20,             # Font size for y-axis tick labels\n",
    "#    'legend.fontsize': 20,             # Font size for legends\n",
    "#    'figure.figsize': [8, 6],          # Size of the plot (width x height)\n",
    "#    'figure.autolayout': True,         # Automatic layout adjustment\n",
    "#    'savefig.format': 'svg',           # Default format for saving figures\n",
    "#    'figure.facecolor': 'none',        # Make the figure face color transparent\n",
    "#    'axes.facecolor': 'none',          # Make the axes face color transparent\n",
    "#    'savefig.transparent': True        # Save figures with transparent background\n",
    "})\n",
    "output_dir = os.getcwd()  # Gets the current working directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# allows for interactive plots\n",
    "#%matplotlib notebook"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "H = H_0 + H_I\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_0 = \\hbar \\omega_a \\sum_{i=1}^{N_{\\text{atoms}}} \\sigma_+^{(i)} \\sigma_-^{(i)} + \\hbar \\sum_{i,j=1}^{N_\\text{{atoms}}} J_{ij} \\sigma_+^{(i)} \\sigma_-^{(j)} \\quad \\text{,} \\quad J_{ij} = \\frac{\\alpha}{|r_i - r_j|^3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_I = \\hbar D \\cdot E(t)\n",
    "\\quad \\text{,} \\quad D = \\mu \\sum_{i=1}^{N_{\\text{atoms}}} \\sigma_+^{(i)} + \\sigma_-^{(i)}\n",
    "\\quad \\text{,} \\quad E(t_i) \\propto \\Omega_{coupling} \\cos(\\pi (t - t_i)) \\delta(t_i)\n",
    "$$\n",
    "\n",
    "### Decay operators single case\n",
    "$$\n",
    "C_{\\text{decay}}^{(i)} = \\sqrt{\\gamma_0} \\sigma_-^{(i)} \\quad\n",
    "C_{\\text{dephase}}^{(i)} = \\sqrt{\\gamma_\\phi} \\sigma_z^{(i)}\n",
    "$$"
   ],
   "id": "fbde5d7951a8a53b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:09.465796Z",
     "start_time": "2025-01-31T16:10:09.445126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Set the system parameters\n",
    "#\n",
    "# ENERGY LANDSCAPE, c = 1, hbar = 1\n",
    "fixed_lam = 1. #\n",
    "alpha     = 1. # coupling strength of the dipoles       Fine structure const?\n",
    "\n",
    "omega_a   = 2 * np.pi / fixed_lam   # energysplitting of the atom, when ground state is set to 0\n",
    "mu        = 1 * omega_a             # Dipole matrix element of each atom\n",
    "omega_R   = 1 * omega_a             # Rabi freq coupling to laser field  for first 2 lasers  -> E_field_0 dot dot Dip_op, parallel\n",
    "\n",
    "# LINBLAD OPS\n",
    "gamma_0   = .3 # decay rate of the atoms\n",
    "gamma_phi = .3 # dephasing rate of the atoms\n",
    "\n",
    "# TOPOLOGY\n",
    "n_chains = 1 # number of chains\n",
    "n_rings  = 1 # number of rings\n",
    "N_atoms  = n_chains * n_rings  # number of atoms\n",
    "\n",
    "distance = 1. # * fixed_lam # defining topology\n",
    "\n",
    "# TIME EVOLUTION\n",
    "last_pulse = 10 # * gamma_0\n",
    "last_det_t = 1 * last_pulse # last time when the system is measured -> t elem 0...last_det_t - T\n",
    "time_steps = 120\n",
    "tau_steps = time_steps\n",
    "T_steps = time_steps // 10\n",
    "approx_T_vals = np.linspace(0, last_det_t, T_steps)  # approximate T values\n",
    "\n",
    "times_t = np.linspace(0, last_det_t, time_steps) # list of times_t\n",
    "T_indices = np.array([np.abs(times_t - x).argmin() for x in approx_T_vals])\n",
    "\n",
    "taus = np.linspace(0, last_det_t, time_steps)  # list of times_t for tau\n",
    "Ts = times_t[T_indices]\n",
    "\n",
    "mean_pos = [0, 0, 0]  # Mean position (can be any point in 3D space)\n",
    "sigma_pos = N_atoms / 10  # Standard deviation for position distribution\n",
    "########################################               define the geometry                 #############################################\n",
    "def chain_positions(distance, N_atoms):\n",
    "    Pos = np.zeros((N_atoms, 3))\n",
    "    for i in range(N_atoms):\n",
    "        Pos[i, 2] = i * distance\n",
    "    return Pos\n",
    "def z_rotation(angle):\n",
    "    return np.array([\n",
    "        [np.cos(angle), -np.sin(angle), 0],\n",
    "        [np.sin(angle),  np.cos(angle), 0],\n",
    "        [0,              0,            1]])\n",
    "def ring_positions(distance, n_chains):\n",
    "    Pos = np.zeros((n_chains, 3))\n",
    "    dphi = 2 * np.pi / n_chains\n",
    "    if n_chains == 1:\n",
    "        radius = 0\n",
    "    else:\n",
    "        radius = distance / 2 / np.sin(np.pi / n_chains)\n",
    "    helper = np.array([radius, 0, 0])\n",
    "    for i in range(n_chains):\n",
    "        rotation_matrix = z_rotation(dphi * i)\n",
    "        Pos[i] = np.matmul(rotation_matrix, helper)\n",
    "    return Pos\n",
    "def cyl_positions(distance, N_atoms, n_chains):\n",
    "    Pos = np.zeros((N_atoms, 3))\n",
    "    Pos_chain = chain_positions(distance, N_atoms // n_chains)\n",
    "    Pos_ring = ring_positions(distance, n_chains)\n",
    "    for i in range(n_chains):\n",
    "        Pos[i * (N_atoms // n_chains): (i + 1) * (N_atoms // n_chains)] = Pos_chain + Pos_ring[i]\n",
    "    return Pos\n",
    "##################                           help functions                                 ##################\n",
    "def count_decimal_digits(number):\n",
    "    # Convert the number to string\n",
    "    str_number = str(number)\n",
    "\n",
    "    # Split the string at the decimal point and count the digits after it\n",
    "    if '.' in str_number:\n",
    "        return len(str_number.split('.')[1])\n",
    "    else:\n",
    "        return 0  # No digits after decimal if it's an integer\n",
    "tolerance = count_decimal_digits(times_t[1]) - 2\n",
    "def truncate_number(number, decimals=0):\n",
    "    factor = 10.0 ** decimals\n",
    "    return int(number * factor) / factor\n",
    "def heaviside(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "def sample_positions(mean_pos, sigma_pos, N_atoms):\n",
    "    positions = []\n",
    "    while len(positions) < N_atoms:\n",
    "        # Sample a new position for the atom\n",
    "        new_position = np.random.normal(loc=mean_pos, scale=sigma_pos, size=3)\n",
    "        # Check if the new position is unique (no duplicates)\n",
    "        if not any(np.allclose(new_position, pos) for pos in positions):\n",
    "            positions.append(new_position)\n",
    "    return np.array(positions)\n",
    "def sample_frequencies(E0, Delta, N_atoms):\n",
    "    # Sample N_atoms frequencies from the Gaussian distribution\n",
    "    frequencies = np.random.normal(loc=E0, scale=Delta/2, size=N_atoms)\n",
    "    return frequencies\n",
    "def plot_positive_color_map(x, y, data, T, sum=False, space=\"real\", type=\"real\", positive=False, safe=False):\n",
    "    \"\"\"\n",
    "    Create a color plot of 2D functional data for positive x and y values only.\n",
    "\n",
    "    Parameters:\n",
    "        x (np.array): 1D array of x values.\n",
    "        y (np.array): 1D array of y values.\n",
    "        data (np.array): 2D array of data values aligned with x and y.\n",
    "        T (float): Temperature parameter to include in plot title and file name.\n",
    "        sum (bool): Whether this is a summed plot (True) or not (False).\n",
    "        space (str): Either 'real' or 'freq' specifying the space of the data.\n",
    "        type (str): Type of data ('real', 'imag', 'abs', or 'phase'). Used only if space=\"freq\".\n",
    "        positive (bool): Whether to use only positive values of x and y.\n",
    "        safe (bool): If True, saves the plot to a file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Convert x and y into 1D arrays if they're not\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if positive:\n",
    "        # Filter for positive x and y values\n",
    "        positive_x_indices = np.where(x > 0)[0]  # Indices where x > 0\n",
    "        positive_y_indices = np.where(y > 0)[0]  # Indices where y > 0\n",
    "        x = x[positive_x_indices]\n",
    "        y = y[positive_y_indices]\n",
    "        data = data[np.ix_(positive_y_indices, positive_x_indices)]\n",
    "\n",
    "    if space == \"real\":\n",
    "        colormap = \"viridis\"\n",
    "        label = r\"$E_{out} \\propto P / E_0$\"\n",
    "        title = f\"2D Spectrum, Real space at T ={T:.2f} (arb. units)\"\n",
    "        if sum:\n",
    "            title = f\"2D Spectrum, Real space sum (arb. units)\"\n",
    "        x_title = r\"$t_{det}$ (arb. units)\"\n",
    "        y_title = r\"$\\tau_{coh}$ (arb. units)\"\n",
    "    elif space == \"freq\":\n",
    "        colormap = \"plasma\"\n",
    "        label = r\"$E_{out} \\propto P / E_0$\"\n",
    "        title = f\"2D Spectrum, Freq space at T ={T:.2f} (arb. units)\"\n",
    "        if sum:\n",
    "            title = f\"2D Spectrum, Freq space sum (arb. units)\"\n",
    "        x_title = r\"$\\omega_{t_{det}}$ (arb. units)\"\n",
    "        y_title = r\"$\\omega_{\\tau_{coh}}$ (arb. units)\"\n",
    "        if type == \"real\":\n",
    "            data = np.real(data)\n",
    "        elif type == \"imag\":\n",
    "            data = np.imag(data)\n",
    "        elif type == \"abs\":\n",
    "            data = np.abs(data)\n",
    "        elif type == \"phase\":\n",
    "            data = np.angle(data)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Type. Must be 'real', 'imag', 'abs', or 'phase'.\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid space. Must be 'real' or 'freq'.\")\n",
    "\n",
    "\n",
    "    # Plot the color map\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pcolormesh(x, y, data, shading=\"auto\", cmap=colormap)\n",
    "    plt.colorbar(label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_title)\n",
    "    plt.ylabel(y_title)\n",
    "    if safe:\n",
    "        file_name_combined = (\n",
    "            f\"Classical_lam{fixed_lam:.1f}_alpha={alpha:.2f}_g_0{gamma_0:.2f}_g_phi{gamma_phi:.2f}_\"\n",
    "            f\"{n_rings}x{n_chains}_dist={distance:.2f}_positive={positive}_space={space}\"\n",
    "        )\n",
    "        if space == \"freq\":\n",
    "            file_name_combined += f\"_type={type}\"\n",
    "        file_name_combined += \".svg\"\n",
    "        save_path_combined = os.path.join(output_dir, file_name_combined)\n",
    "        plt.savefig(save_path_combined)\n",
    "    plt.show()\n",
    "def Hamilton0(distance, n_rings, n_chains):\n",
    "    N_atoms = n_chains * n_rings\n",
    "    Pos = cyl_positions(distance, N_atoms, n_chains) # sample_positions(mean_pos, sigma_pos, N_atoms)        #\n",
    "    atom_frequencies = sample_frequencies(omega_a, 0.0125 * omega_a, N_atoms) # [omega_a] * N_atoms #\n",
    "    H = 0\n",
    "    for a in range(N_atoms):\n",
    "        for b in range(N_atoms):\n",
    "            op = sm_list[a].dag() * sm_list[b]\n",
    "            if a != b:\n",
    "                ra, rb = Pos[a, :], Pos[b, :]\n",
    "                H += alpha / (np.linalg.norm(rb-ra))**3 * op\n",
    "            else:\n",
    "                H += atom_frequencies[a] *op # Diagonals except for |0><0|\n",
    "    return H\n",
    "def El_field(t, args):\n",
    "    t0 = args['time']\n",
    "    Delta = args['Delta']\n",
    "    E = np.exp(1j*(args['omega'] * t + args['phi']))\n",
    "    E += np.conjugate(E)\n",
    "    # secure the field is 0 outside short range\n",
    "    E *= np.cos(np.pi * (t - t0) / (2 * Delta))**2 * heaviside(t - (t0 - Delta)) * heaviside(t0 + Delta - t)\n",
    "\n",
    "    return args['E0'] * E\n",
    "\n",
    "# Define the ground & the excited states\n",
    "# atomic dofs\n",
    "atom_g = basis(N_atoms + 1, 0)\n",
    "atom_es = [basis(N_atoms + 1, i) for i in range(1, N_atoms + 1)]\n",
    "# initial state\n",
    "psiini = atom_g # = |g>_atom\n",
    "\n",
    "# combined dofs\n",
    "sm_list = []    # lowering operators of atomic system\n",
    "Dip_op = 0         # collective sigma_x operator for the system\n",
    "for i in range(N_atoms):\n",
    "    op = atom_g * atom_es[i].dag()\n",
    "    sm_list.append(op)\n",
    "    Dip_op += mu * op + mu * op.dag()\n",
    "H0 = Hamilton0(distance, n_rings, n_chains)\n",
    "\n",
    "# Jump / Expect Operators          # Define the decay collapse and dephasing operator for each spin\n",
    "# Collapse operators\n",
    "c_op2 = [np.sqrt(gamma_0) * op for op in sm_list]                         # Individual atom decays\n",
    "c_op4 = [np.sqrt(gamma_phi) * commutator(op.dag(), op) for op in sm_list] # Individual atom dephasing\n",
    "c_op_list = c_op2 + c_op4  # Combine all collapse operators\n",
    "# Expectation operators for measuring populations across atomic ground and excited levels\n",
    "e_op_list = [ket2dm(basis(N_atoms + 1, i)) for i in range(N_atoms + 1)]\n",
    "\n",
    "#\n",
    "# evolution with t\n",
    "#\n",
    "# create the time dependant evolution\n",
    "Omegas = [omega_R, omega_R, omega_R/10] # Probe pulse is smaller\n",
    "omegas = [omega_a, omega_a, omega_a]    # The laser is on resonant\n",
    "Delta_ts = [last_pulse/time_steps, last_pulse/time_steps, last_pulse/time_steps] # narrow width of the pulses\n",
    "HI = [-Dip_op, El_field] # interaction Hamiltonian with function-based time dependence\n",
    "H = [H0, HI]\n",
    "options = Options(store_states=True)\n",
    "\n",
    "\n",
    "#\n",
    "# PREPROCESSING\n",
    "#\n",
    "# Phase cycling\n",
    "phases = [-1 * i * np.pi / 2 for i in range(4)]"
   ],
   "id": "76bb23c3f08969f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leopold/PycharmProjects/Master_thesis/.venv/lib/python3.12/site-packages/qutip/solver/options.py:16: FutureWarning: Dedicated options class are no longer needed, options should be passed as dict to solvers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:09.567983Z",
     "start_time": "2025-01-31T16:10:09.559461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# CALCULATIONS\n",
    "#\n",
    "\n",
    "# (first laser pulse)\n",
    "times_0 = times_t\n",
    "# Iterate over the phi values\n",
    "def compute_first_pulse(phi_1):\n",
    "    # Set the arguments for this particular phi\n",
    "    args_0 = {\n",
    "        'phi': phi_1,\n",
    "        'time': Delta_ts[0],\n",
    "        'omega': omegas[0],\n",
    "        'Delta': Delta_ts[0],\n",
    "        'E0': Omegas[0]\n",
    "    }\n",
    "\n",
    "    # Solve the system using mesolve\n",
    "    result_0 = mesolve(H, psiini, times_0, c_ops=c_op_list, e_ops=e_op_list, args=args_0, options=options)\n",
    "\n",
    "    # Prepare the data dictionary for this particular phi value\n",
    "    current_dict = {}\n",
    "    for i in range(len(times_0)):\n",
    "        if (2 * Delta_ts[0] <= times_0[i] <= last_pulse - 2 * (Delta_ts[1] + Delta_ts[2])):\n",
    "            current_dict[i] = result_0.states[i]\n",
    "    return current_dict\n",
    "def compute_second_pulse(phi_2, res_1):\n",
    "    data_dict_stage2_local = {}\n",
    "    times_1_dict = {}  # To store times_1 for each combination\n",
    "\n",
    "    for i, psiini_1 in res_1.items():\n",
    "        times_1 = times_t[i:]\n",
    "\n",
    "        args_1 = {\n",
    "            'phi': phi_2,  # Use phi_2 for the second pulse\n",
    "            'time': times_1[0] + Delta_ts[1],\n",
    "            'omega': omegas[1],\n",
    "            'Delta': Delta_ts[1],\n",
    "            'E0': Omegas[1]\n",
    "        }\n",
    "\n",
    "        # Solve the system using mesolve for the second pulse\n",
    "        result_1 = mesolve(H, psiini_1, times_1, c_ops=c_op_list, e_ops=e_op_list, args=args_1, options=options)\n",
    "\n",
    "        current_dict = {}\n",
    "        for j in range(len(times_1)):  # Save only the states that make sense\n",
    "            if (times_t[i] + 2 * Delta_ts[1] <= times_1[j] <= last_pulse - 2 * Delta_ts[2]):\n",
    "                current_dict[j] = result_1.states[j]\n",
    "\n",
    "        if current_dict:  # Check if the dictionary is not empty\n",
    "            data_dict_stage2_local[i] = current_dict\n",
    "            times_1_dict[i] = times_1  # Store times_1 for later access\n",
    "\n",
    "    return data_dict_stage2_local, times_1_dict\n",
    "def compute_third_pulse(res_2):\n",
    "    data_dict = {}\n",
    "    for i, dic1 in res_2[0].items():\n",
    "        times_1 = res_2[1][i]\n",
    "        count = 0\n",
    "        # Iterate over the T values (waiting times) and calculate the last laser pulse\n",
    "        for j, psiini_2 in dic1.items():\n",
    "            times_2 = times_1[j:]\n",
    "            T_j = times_1[j] + Delta_ts[2] - times_1[0] - Delta_ts[1]  # waiting_time_j\n",
    "            T_j = truncate_number(T_j, tolerance - 2)\n",
    "            T_c = truncate_number(Ts[count], tolerance - 2)\n",
    "            # if the delay T is smaller than the current pulse difference, take next one\n",
    "            while T_c < T_j and count < len(Ts) - 1:\n",
    "                count += 1\n",
    "                T_c = truncate_number(Ts[count], tolerance - 2)\n",
    "\n",
    "            # ONLY NOW MAKE THE LAST PULSE\n",
    "            if np.isclose(T_j, T_c):\n",
    "                # Define the parameters for the last laser pulse\n",
    "                args_2 = {\n",
    "                    'phi': 0,  # Last pulse has no phase kick\n",
    "                    'time': times_2[0] + Delta_ts[2],  # Duration for the 2nd pulse\n",
    "                    'omega': omegas[2],  # Omega for the 2nd pulse\n",
    "                    'Delta': Delta_ts[2],  # Delta for the 2nd pulse\n",
    "                    'E0': Omegas[2]  # E0 for the 2nd pulse\n",
    "                }\n",
    "\n",
    "                # Solve the system using mesolve for the last pulse\n",
    "                result_2 = mesolve(H, psiini_2, times_2, c_ops=c_op_list, e_ops=e_op_list, args=args_2, options=options)\n",
    "\n",
    "                # Iterate over the states in result_2 and store the ones that meet the condition\n",
    "                for k in range(len(times_2)):\n",
    "                    if (times_1[j] + 2 * Delta_ts[2] <= times_2[k] <= last_det_t):\n",
    "                        tau_i = times_1[0] + Delta_ts[1] - Delta_ts[0]\n",
    "                        t_k = times_2[k] - times_2[0] - Delta_ts[2]\n",
    "                        tau_i = truncate_number(tau_i, tolerance - 2)\n",
    "                        t_k = truncate_number(t_k, tolerance - 2)\n",
    "\n",
    "                        if T_j not in data_dict:\n",
    "                            data_dict[T_j] = {}\n",
    "                        if tau_i not in data_dict[T_j]:\n",
    "                            data_dict[T_j][tau_i] = {}\n",
    "\n",
    "\n",
    "                        # Compute the polarization and store it in the dictionary\n",
    "                        Polarization = expect(Dip_op, result_2.states[k]) / omega_R\n",
    "                        data_dict[T_j][tau_i][t_k] = Polarization\n",
    "    return data_dict\n",
    "# Wrapper function to process each combination of phi_1 and phi_2\n",
    "def process_phi_combination(phi_1, phi_2):\n",
    "    # Step 1: Compute the first pulse for phi_1\n",
    "    first_pulse_data = compute_first_pulse(phi_1)\n",
    "\n",
    "    # Step 2: Compute the second pulse with the result from the first pulse\n",
    "    second_pulse_data = compute_second_pulse(phi_2, first_pulse_data)\n",
    "\n",
    "    # Step 3: Compute the third pulse with the result from the second pulse\n",
    "    third_pulse_data = compute_third_pulse(second_pulse_data)\n",
    "    return third_pulse_data"
   ],
   "id": "c98df78b0b30e54f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:29.426170Z",
     "start_time": "2025-01-31T16:10:09.607836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize results dictionary\n",
    "all_results = {}\n",
    "# Parallelize the computation for all combinations of phi_1 and phi_2\n",
    "max_workers = min(len(phases) ** 2, os.cpu_count())  # Limit workers based on available CPUs\n",
    "with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Track each future and corresponding (phi_1, phi_2)\n",
    "    futures = {executor.submit(process_phi_combination, phi_1, phi_2): (phi_1, phi_2)\n",
    "               for phi_1 in phases for phi_2 in phases}\n",
    "\n",
    "    # Collect results as they complete\n",
    "    for future in futures:\n",
    "        phi_1, phi_2 = futures[future]  # Retrieve the associated (phi_1, phi_2)\n",
    "        third_pulse_data = future.result()\n",
    "        if third_pulse_data is not None:\n",
    "            all_results[(phi_1, phi_2)] = third_pulse_data\n",
    "\n",
    "#all_results[(0,0)] # now contains the results keyed by (phi_1, phi_2)"
   ],
   "id": "f95f681b138fe329",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:29.452236Z",
     "start_time": "2025-01-31T16:10:29.445491Z"
    }
   },
   "cell_type": "code",
   "source": "all_results[(0,0)][0.9243697478991].keys()",
   "id": "bc0b5996e389644f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0.1680672268907, 0.2521008403361, 0.3361344537815, 0.4201680672268, 0.5042016806722, 0.5882352941176, 0.672268907563, 0.7563025210084, 0.8403361344537, 0.9243697478991, 1.0084033613445, 1.0924369747899, 1.1764705882352, 1.2605042016806, 1.344537815126, 1.4285714285714, 1.5126050420168, 1.5966386554621, 1.6806722689075, 1.7647058823529, 1.8487394957983, 1.9327731092436, 2.016806722689, 2.1008403361344, 2.1848739495798, 2.2689075630252, 2.3529411764705, 2.4369747899159, 2.5210084033613, 2.6050420168067, 2.6890756302521, 2.7731092436974, 2.8571428571428, 2.9411764705882, 3.0252100840336, 3.1092436974789, 3.1932773109243, 3.2773109243697, 3.3613445378151, 3.4453781512605, 3.5294117647058, 3.6134453781512, 3.6974789915966, 3.781512605042, 3.8655462184873, 3.9495798319327, 4.0336134453781, 4.1176470588235, 4.2016806722689, 4.2857142857142, 4.3697478991596, 4.453781512605, 4.5378151260504, 4.6218487394957, 4.7058823529411, 4.7899159663865, 4.8739495798319, 4.9579831932773, 5.0420168067226, 5.126050420168, 5.2100840336134, 5.2941176470588, 5.3781512605042, 5.4621848739495, 5.5462184873949, 5.6302521008403, 5.7142857142857, 5.798319327731, 5.8823529411764, 5.9663865546218, 6.0504201680672, 6.1344537815126, 6.2184873949579, 6.3025210084033, 6.3865546218487, 6.4705882352941, 6.5546218487394, 6.6386554621848, 6.7226890756302, 6.8067226890756, 6.890756302521, 6.9747899159663, 7.0588235294117, 7.1428571428571, 7.2268907563025, 7.3109243697479, 7.3949579831932, 7.4789915966386, 7.563025210084, 7.6470588235294, 7.7310924369747, 7.8151260504201, 7.8991596638655, 7.9831932773109, 8.0672268907563, 8.1512605042016, 8.235294117647, 8.3193277310924, 8.4033613445378, 8.4873949579831, 8.5714285714285, 8.6554621848739, 8.7394957983193, 8.8235294117647, 8.90756302521])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:29.584185Z",
     "start_time": "2025-01-31T16:10:29.577392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(list(all_results[(0,0)][0.9243697478991].keys())))\n",
    "print(len(list(all_results[(0,0)][0.9243697478991][0.1680672268907].keys())))"
   ],
   "id": "bd02315b2b8eb804",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "105\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:11:03.001483Z",
     "start_time": "2025-01-31T16:11:02.478664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the averaged_data_dict\n",
    "averaged_data_dict = {}\n",
    "\n",
    "# Collect all unique T_j values from all_results dictionary\n",
    "unique_T_j = {T_key for (phi_1, phi_2) in all_results for T_key in all_results[(phi_1, phi_2)]}\n",
    "\n",
    "# Iterate over unique T_j values\n",
    "for T_j in unique_T_j:\n",
    "    averaged_data_dict[T_j] = {}\n",
    "\n",
    "    # Collect all unique tau_i values for the current T_j\n",
    "    unique_tau_i = {tau_key for (phi_1, phi_2) in all_results\n",
    "                    if T_j in all_results[(phi_1, phi_2)]\n",
    "                    for tau_key in all_results[(phi_1, phi_2)][T_j]}\n",
    "\n",
    "    # Iterate over unique tau_i values\n",
    "    for tau_i in unique_tau_i:\n",
    "        averaged_data_dict[T_j][tau_i] = {}\n",
    "\n",
    "        # Collect all unique t_k values for the current (T_j, tau_i)\n",
    "        unique_t_k = {t_key for (phi_1, phi_2) in all_results\n",
    "                      if T_j in all_results[(phi_1, phi_2)] and tau_i in all_results[(phi_1, phi_2)][T_j]\n",
    "                      for t_key in all_results[(phi_1, phi_2)][T_j][tau_i]}\n",
    "\n",
    "        # Iterate over unique t_k values\n",
    "        for t_k in unique_t_k:\n",
    "            # Calculate the sum of polarization values across all phase combinations\n",
    "            polarization_sum = sum(\n",
    "                all_results[(phi_1, phi_2)][T_j][tau_i].get(t_k, 0)\n",
    "                for (phi_1, phi_2) in all_results\n",
    "                if T_j in all_results[(phi_1, phi_2)] and tau_i in all_results[(phi_1, phi_2)][T_j]\n",
    "            )\n",
    "\n",
    "            # Count the number of valid entries for averaging\n",
    "            valid_count = sum(\n",
    "                1 for (phi_1, phi_2) in all_results\n",
    "                if T_j in all_results[(phi_1, phi_2)]\n",
    "                and tau_i in all_results[(phi_1, phi_2)][T_j]\n",
    "                and t_k in all_results[(phi_1, phi_2)][T_j][tau_i]\n",
    "            )\n",
    "\n",
    "            # Store the averaged polarization value\n",
    "            averaged_data_dict[T_j][tau_i][t_k] = None#polarization_sum / max(1, valid_count)\n",
    "\n",
    "#averaged_data_dict[list(unique_T_j)[0]]\n",
    "print(len(list(averaged_data_dict[0.9243697478991].keys())))\n",
    "print(len(list(averaged_data_dict[0.9243697478991][0.1680672268907].keys())))\n",
    "sorted_tau_keys = sorted(averaged_data_dict[0.9243697478991].keys())\n",
    "print(sorted_tau_keys)\n",
    "\n",
    "# Extract and sort keys for tau_i = 0.1680672268907 within T_j = 0.9243697478991\n",
    "sorted_t_keys = sorted(averaged_data_dict[0.9243697478991][0.1680672268907].keys())\n",
    "sorted_t_keys = np.array(sorted(set(t for tau in taus for t in averaged_data_dict[.9243697478991][tau].keys()))) # TODO SOME PROBLEM HERE\n",
    "print(sorted_t_keys)\n",
    "print(len(sorted_t_keys), len(sorted_tau_keys))"
   ],
   "id": "5bd169e84a6fa78f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "105\n",
      "[0.1680672268907, 0.2521008403361, 0.3361344537815, 0.4201680672268, 0.5042016806722, 0.5882352941176, 0.672268907563, 0.7563025210084, 0.8403361344537, 0.9243697478991, 1.0084033613445, 1.0924369747899, 1.1764705882352, 1.2605042016806, 1.344537815126, 1.4285714285714, 1.5126050420168, 1.5966386554621, 1.6806722689075, 1.7647058823529, 1.8487394957983, 1.9327731092436, 2.016806722689, 2.1008403361344, 2.1848739495798, 2.2689075630252, 2.3529411764705, 2.4369747899159, 2.5210084033613, 2.6050420168067, 2.6890756302521, 2.7731092436974, 2.8571428571428, 2.9411764705882, 3.0252100840336, 3.1092436974789, 3.1932773109243, 3.2773109243697, 3.3613445378151, 3.4453781512605, 3.5294117647058, 3.6134453781512, 3.6974789915966, 3.781512605042, 3.8655462184873, 3.9495798319327, 4.0336134453781, 4.1176470588235, 4.2016806722689, 4.2857142857142, 4.3697478991596, 4.453781512605, 4.5378151260504, 4.6218487394957, 4.7058823529411, 4.7899159663865, 4.8739495798319, 4.9579831932773, 5.0420168067226, 5.126050420168, 5.2100840336134, 5.2941176470588, 5.3781512605042, 5.4621848739495, 5.5462184873949, 5.6302521008403, 5.7142857142857, 5.798319327731, 5.8823529411764, 5.9663865546218, 6.0504201680672, 6.1344537815126, 6.2184873949579, 6.3025210084033, 6.3865546218487, 6.4705882352941, 6.5546218487394, 6.6386554621848, 6.7226890756302, 6.8067226890756, 6.890756302521, 6.9747899159663, 7.0588235294117, 7.1428571428571, 7.2268907563025, 7.3109243697479, 7.3949579831932, 7.4789915966386, 7.563025210084, 7.6470588235294, 7.7310924369747, 7.8151260504201, 7.8991596638655, 7.9831932773109, 8.0672268907563, 8.1512605042016, 8.235294117647, 8.3193277310924, 8.4033613445378, 8.4873949579831, 8.5714285714285, 8.6554621848739, 8.7394957983193, 8.8235294117647, 8.90756302521]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "np.float64(0.0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 53\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Extract and sort keys for tau_i = 0.1680672268907 within T_j = 0.9243697478991\u001B[39;00m\n\u001B[1;32m     52\u001B[0m sorted_t_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(averaged_data_dict[\u001B[38;5;241m0.9243697478991\u001B[39m][\u001B[38;5;241m0.1680672268907\u001B[39m]\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[0;32m---> 53\u001B[0m sorted_t_keys \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtau\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtaus\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43maveraged_data_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.9243697478991\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtau\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(sorted_t_keys)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(sorted_t_keys), \u001B[38;5;28mlen\u001B[39m(sorted_tau_keys))\n",
      "Cell \u001B[0;32mIn[8], line 53\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Extract and sort keys for tau_i = 0.1680672268907 within T_j = 0.9243697478991\u001B[39;00m\n\u001B[1;32m     52\u001B[0m sorted_t_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(averaged_data_dict[\u001B[38;5;241m0.9243697478991\u001B[39m][\u001B[38;5;241m0.1680672268907\u001B[39m]\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[0;32m---> 53\u001B[0m sorted_t_keys \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mset\u001B[39m(t \u001B[38;5;28;01mfor\u001B[39;00m tau \u001B[38;5;129;01min\u001B[39;00m taus \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[43maveraged_data_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.9243697478991\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtau\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mkeys())))\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(sorted_t_keys)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(sorted_t_keys), \u001B[38;5;28mlen\u001B[39m(sorted_tau_keys))\n",
      "\u001B[0;31mKeyError\u001B[0m: np.float64(0.0)"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# PLOTTING\n",
    "#\n",
    "# Function to prepare data for a single T value\n",
    "def prepare_data_for_T(T):\n",
    "    taus = np.array(list(averaged_data_dict[T].keys()))\n",
    "    ts = np.array(sorted(set(t for tau in taus for t in averaged_data_dict[T][tau].keys())))\n",
    "    print(len(ts), len(taus))\n",
    "    data = np.zeros((len(ts), len(taus)))  # or dtype=np.complex128 if needed\n",
    "    # Populate the 2D data array with the corresponding expect_vals\n",
    "    for i, t in enumerate(ts):  # Iterate over ts\n",
    "        for j, tau in enumerate(taus):  # Iterate over taus\n",
    "            if t in averaged_data_dict[T][tau]:  # Check if t exists for the given tau\n",
    "                data[i, j] = averaged_data_dict[T][tau][t]  # Assign expect_val\n",
    "    return T, {\n",
    "        \"ts\": ts,  # Local ts specific to T\n",
    "        \"taus\": taus,  # Local taus specific to T\n",
    "        \"data\": data,  # Local data\n",
    "    }\n",
    "\n",
    "prepare_data_for_T(.9243697478991)"
   ],
   "id": "1e4bad35ae59f1cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Parallelize the preparation of data for all T values\n",
    "global_ts, global_taus = None, None\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    results = executor.map(prepare_data_for_T, sorted(averaged_data_dict.keys()))\n",
    "    i = 0\n",
    "    for T, data in results:\n",
    "        #print(T)\n",
    "        if i == 0:\n",
    "            smallest_key = T\n",
    "            global_ts = data[\"ts\"]\n",
    "            print(len(data[\"ts\"]), len(data[\"taus\"]))\n",
    "            global_taus = data[\"taus\"]\n",
    "            # Sum all data into global sum\n",
    "            global_data_time = np.zeros((len(global_ts), len(global_taus)))\n",
    "            global_data_freq = np.zeros((len(global_ts), len(global_taus)), dtype=np.complex64)\n",
    "\n",
    "        i += 1\n",
    "        taus = data[\"taus\"]  # Local taus for the current T\n",
    "        ts = data[\"ts\"]  # Local ts for the current T\n",
    "        if len(ts) < 4 or len(taus) < 4:  # Skip small data\n",
    "            continue\n",
    "\n",
    "        data_time = data[\"data\"]  # Aligned 2D data\n",
    "\n",
    "        data_extended_time = np.zeros_like(global_data_time)\n",
    "\n",
    "        # Map taus and ts to global indices\n",
    "        for i, t in enumerate(ts):\n",
    "            for j, tau in enumerate(taus):\n",
    "                global_i = np.where(global_ts == t)[0]  # Find the index of t in global_ts\n",
    "                global_j = np.where(global_taus == tau)[0]\n",
    "                data_extended_time[global_i, global_j] = data_time[i, j]\n",
    "\n",
    "        data_extended_freq = np.fft.fft2(data_extended_time)\n",
    "        print(global_ts.shape, global_taus.shape, data_extended_time.shape)\n",
    "        plot_positive_color_map(global_ts, global_taus, data_extended_time, T, safe = False)\n",
    "        #plot_positive_color_map(global_t_freqs, global_tau_freqs, data_extended_freq, T, space = \"freq\", type = \"abs\", positive = True, safe = False)\n",
    "\n",
    "\n",
    "        global_data_time += data_extended_time\n",
    "        global_data_freq += data_extended_freq\n",
    "\n",
    "global_data_time /= i\n",
    "global_data_freq /= i\n",
    "\n",
    "global_t_freqs = (np.fft.fftfreq(len(global_ts), d=(global_ts[1] - global_ts[0])))  # Frequency axis for detection time\n",
    "global_tau_freqs = (np.fft.fftfreq(len(global_taus), d=(global_taus[1] - global_taus[0])))  # Frequency axis for excitation time\n",
    "\n",
    "#plot_positive_color_map(global_ts, global_taus, global_data_time, T, sum = True, safe = False)\n",
    "#plot_positive_color_map(global_t_freqs, global_tau_freqs, global_data_freq, T, sum = True, space = \"freq\", type = \"abs\", positive = True, safe = False)"
   ],
   "id": "a3df021e763b6085",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
