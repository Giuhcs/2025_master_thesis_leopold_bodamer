{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T15:33:38.278289Z",
     "start_time": "2025-02-04T15:33:37.474020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "from qutip import * \n",
    "import os\n",
    "\n",
    "# Matplotlib Einstellungen gemäß den LaTeX-Caption-Formatierungen\n",
    "plt.rcParams.update({\n",
    "#    'text.usetex': True,              # Enable LaTeX for text rendering\n",
    "#    'font.family': 'serif',           # Use a serif font family\n",
    "#    'font.serif': 'Palatino',         # Set Palatino as the serif font\n",
    "#    'text.latex.preamble': r'\\usepackage{amsmath}',\n",
    "#    'font.size': 20,                   # Font size for general text\n",
    "#    'axes.titlesize': 20,              # Font size for axis titles\n",
    "#    'axes.labelsize': 20,              # Font size for axis labels\n",
    "#    'xtick.labelsize': 20,             # Font size for x-axis tick labels\n",
    "#    'ytick.labelsize': 20,             # Font size for y-axis tick labels\n",
    "#    'legend.fontsize': 20,             # Font size for legends\n",
    "#    'figure.figsize': [8, 6],          # Size of the plot (width x height)\n",
    "#    'figure.autolayout': True,         # Automatic layout adjustment\n",
    "#    'savefig.format': 'svg',           # Default format for saving figures\n",
    "#    'figure.facecolor': 'none',        # Make the figure face color transparent\n",
    "#    'axes.facecolor': 'none',          # Make the axes face color transparent\n",
    "#    'savefig.transparent': True        # Save figures with transparent background\n",
    "})\n",
    "output_dir = os.getcwd()  # Gets the current working directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# allows for interactive plots\n",
    "#%matplotlib notebook"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "H = H_0 + H_I\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_0 = \\hbar \\omega_a \\sum_{i=1}^{N_{\\text{atoms}}} \\sigma_+^{(i)} \\sigma_-^{(i)} + \\hbar \\sum_{i,j=1}^{N_\\text{{atoms}}} J_{ij} \\sigma_+^{(i)} \\sigma_-^{(j)} \\quad \\text{,} \\quad J_{ij} = \\frac{\\alpha}{|r_i - r_j|^3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_I = \\hbar D \\cdot E(t)\n",
    "\\quad \\text{,} \\quad D = \\mu \\sum_{i=1}^{N_{\\text{atoms}}} \\sigma_+^{(i)} + \\sigma_-^{(i)}\n",
    "\\quad \\text{,} \\quad E(t_i) \\propto \\Omega_{coupling} \\cos(\\pi (t - t_i)) \\delta(t_i)\n",
    "$$\n",
    "\n",
    "### Decay operators single case\n",
    "$$\n",
    "C_{\\text{decay}}^{(i)} = \\sqrt{\\gamma_0} \\sigma_-^{(i)} \\quad\n",
    "C_{\\text{dephase}}^{(i)} = \\sqrt{\\gamma_\\phi} \\sigma_z^{(i)}\n",
    "$$"
   ],
   "id": "fbde5d7951a8a53b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T15:45:38.705698Z",
     "start_time": "2025-02-04T15:45:38.686268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Set the system parameters\n",
    "#\n",
    "# ENERGY LANDSCAPE, c = 1, hbar = 1\n",
    "fixed_lam = 1. #\n",
    "alpha     = 1. # coupling strength of the dipoles       Fine structure const?\n",
    "\n",
    "omega_a   = 2 * np.pi / fixed_lam   # energysplitting of the atom, when ground state is set to 0\n",
    "mu        = 1 * omega_a             # Dipole matrix element of each atom\n",
    "omega_R   = 1 * omega_a             # Rabi freq coupling to laser field  for first 2 lasers  -> E_field_0 dot dot Dip_op, parallel\n",
    "\n",
    "# LINBLAD OPS\n",
    "gamma_0   = .1 # decay rate of the atoms\n",
    "gamma_phi = .1 # dephasing rate of the atoms\n",
    "\n",
    "# TOPOLOGY\n",
    "n_chains = 1 # number of chains\n",
    "n_rings  = 1 # number of rings\n",
    "N_atoms  = n_chains * n_rings  # number of atoms\n",
    "\n",
    "distance = 1. # * fixed_lam # defining topology\n",
    "\n",
    "# TIME EVOLUTION\n",
    "t_max = 10  # Maximum time, replace with the required value\n",
    "fine_steps = 100  # Number of steps for high-resolution\n",
    "medium_steps = fine_steps//1  # Number of steps for medium resolution\n",
    "sparse_steps = medium_steps//10  # Number of steps for medium resolution\n",
    "\n",
    "# High-resolution time array\n",
    "times = np.linspace(0, t_max, fine_steps)\n",
    "\n",
    "# Sparse time array\n",
    "times_T = np.linspace(0, t_max, sparse_steps)\n",
    "mean_pos = [0, 0, 0]  # Mean position (can be any point in 3D space)\n",
    "sigma_pos = N_atoms / 10  # Standard deviation for position distribution\n",
    "########################################               define the geometry                 #############################################\n",
    "def chain_positions(distance, N_atoms):\n",
    "    Pos = np.zeros((N_atoms, 3))\n",
    "    for i in range(N_atoms):\n",
    "        Pos[i, 2] = i * distance\n",
    "    return Pos\n",
    "def z_rotation(angle):\n",
    "    return np.array([\n",
    "        [np.cos(angle), -np.sin(angle), 0],\n",
    "        [np.sin(angle),  np.cos(angle), 0],\n",
    "        [0,              0,            1]])\n",
    "def ring_positions(distance, n_chains):\n",
    "    Pos = np.zeros((n_chains, 3))\n",
    "    dphi = 2 * np.pi / n_chains\n",
    "    if n_chains == 1:\n",
    "        radius = 0\n",
    "    else:\n",
    "        radius = distance / 2 / np.sin(np.pi / n_chains)\n",
    "    helper = np.array([radius, 0, 0])\n",
    "    for i in range(n_chains):\n",
    "        rotation_matrix = z_rotation(dphi * i)\n",
    "        Pos[i] = np.matmul(rotation_matrix, helper)\n",
    "    return Pos\n",
    "def cyl_positions(distance, N_atoms, n_chains):\n",
    "    Pos = np.zeros((N_atoms, 3))\n",
    "    Pos_chain = chain_positions(distance, N_atoms // n_chains)\n",
    "    Pos_ring = ring_positions(distance, n_chains)\n",
    "    for i in range(n_chains):\n",
    "        Pos[i * (N_atoms // n_chains): (i + 1) * (N_atoms // n_chains)] = Pos_chain + Pos_ring[i]\n",
    "    return Pos\n",
    "##################                           help functions                                 ##################\n",
    "def sample_positions(mean_pos, sigma_pos, N_atoms):\n",
    "    positions = []\n",
    "    while len(positions) < N_atoms:\n",
    "        # Sample a new position for the atom\n",
    "        new_position = np.random.normal(loc=mean_pos, scale=sigma_pos, size=3)\n",
    "        # Check if the new position is unique (no duplicates)\n",
    "        if not any(np.allclose(new_position, pos) for pos in positions):\n",
    "            positions.append(new_position)\n",
    "    return np.array(positions)\n",
    "def sample_frequencies(E0, Delta, N_atoms):\n",
    "    # Sample N_atoms frequencies from the Gaussian distribution\n",
    "    frequencies = np.random.normal(loc=E0, scale=Delta/2, size=N_atoms)\n",
    "    return frequencies\n",
    "\n",
    "def plot_positive_color_map(x, y, data, T = np.inf, space=\"real\", type=\"real\", positive=False, safe=False, output_dir=None, fixed_lam=None, alpha=None, gamma_0=None, gamma_phi=None, n_rings=None, n_chains=None, distance=None):\n",
    "    \"\"\"\n",
    "    Create a color plot of 2D functional data for positive x and y values only.\n",
    "\n",
    "    Parameters:\n",
    "        x (np.array): 1D array of x values.\n",
    "        y (np.array): 1D array of y values.\n",
    "        data (np.array): 2D array of data values aligned with x and y.\n",
    "        T (float): Temperature parameter to include in plot title and file name.\n",
    "        space (str): Either 'real' or 'freq' specifying the space of the data.\n",
    "        type (str): Type of data ('real', 'imag', 'abs', or 'phase'). Used only if space=\"freq\".\n",
    "        positive (bool): Whether to use only positive values of x and y.\n",
    "        safe (bool): If True, saves the plot to a file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Convert x and y into 1D arrays if they're not\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if positive:\n",
    "        # Filter for positive x and y values\n",
    "        positive_x_indices = np.where(x > 0)[0]  # Indices where x > 0\n",
    "        positive_y_indices = np.where(y > 0)[0]  # Indices where y > 0\n",
    "        x = x[positive_x_indices]\n",
    "        y = y[positive_y_indices]\n",
    "        data = data[np.ix_(positive_y_indices, positive_x_indices)]\n",
    "\n",
    "    if space == \"real\":\n",
    "        colormap = \"viridis\"\n",
    "        label = r\"$E_{out} \\propto P / E_0$\"\n",
    "        title = f\"Real space 2D Spectrum (arb. units)\"\n",
    "        if T != np.inf:\n",
    "            title += f\" at T ={T:.2f}\"\n",
    "        x_title = r\"$t_{det}$ (arb. units)\"\n",
    "        y_title = r\"$\\tau_{coh}$ (arb. units)\"\n",
    "    elif space == \"freq\":\n",
    "        if type == \"real\":\n",
    "            title = f\"Freq space, Real 2D Spectrum (arb. units)\"\n",
    "            data = np.real(data)\n",
    "        elif type == \"imag\":\n",
    "            title = f\"Freq space, Imag 2D Spectrum (arb. units)\"\n",
    "            data = np.imag(data)\n",
    "        elif type == \"abs\":\n",
    "            title = f\"Freq space, Abs 2D Spectrum (arb. units)\"\n",
    "            data = np.abs(data)\n",
    "        elif type == \"phase\":\n",
    "            title = \"Freq space, Phase 2D Spectrum (arb. units)\"\n",
    "            data = np.angle(data)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Type. Must be 'real', 'imag', 'abs', or 'phase'.\")\n",
    "\n",
    "        colormap = \"plasma\"\n",
    "        label = r\"$E_{out} \\propto P / E_0$\"\n",
    "        if T != np.inf:\n",
    "            title += f\" at T ={T:.2f}\"\n",
    "\n",
    "        x_title = r\"$\\omega_{t_{det}}$ (arb. units)\"\n",
    "        y_title = r\"$\\omega_{\\tau_{coh}}$ (arb. units)\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid space. Must be 'real' or 'freq'.\")\n",
    "\n",
    "    # Check and adjust the dimensions of x, y, and data\n",
    "    if data.shape[1] != len(x):\n",
    "        raise ValueError(f\"Length of x ({len(x)}) must match the number of columns in data ({data.shape[1]}).\")\n",
    "    if data.shape[0] != len(y):\n",
    "        raise ValueError(f\"Length of y ({len(y)}) must match the number of rows in data ({data.shape[0]}).\")\n",
    "\n",
    "    # Add 1 to the dimensions of x and y for correct pcolormesh behavior\n",
    "    x = np.concatenate([x, [x[-1] + (x[-1] - x[-2])]])  # Add an extra value for the last x edge\n",
    "    y = np.concatenate([y, [y[-1] + (y[-1] - y[-2])]])  # Add an extra value for the last y edge\n",
    "\n",
    "    # Plot the color map\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pcolormesh(x, y, data / omega_R, shading=\"auto\", cmap=colormap)\n",
    "    plt.colorbar(label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_title)\n",
    "    plt.ylabel(y_title)\n",
    "\n",
    "    # Save the plot if safe is True\n",
    "    if safe and output_dir is not None:\n",
    "        file_name_combined = (\n",
    "            f\"Classical_lam{fixed_lam:.1f}_alpha={alpha:.2f}_g_0{gamma_0:.2f}_g_phi{gamma_phi:.2f}_\"\n",
    "            f\"{n_rings}x{n_chains}_dist={distance:.2f}_positive={positive}_space={space}\"\n",
    "        )\n",
    "        if space == \"freq\":\n",
    "            file_name_combined += f\"_type={type}\"\n",
    "        file_name_combined += \".svg\"\n",
    "        save_path_combined = os.path.join(output_dir, file_name_combined)\n",
    "        plt.savefig(save_path_combined)\n",
    "\n",
    "    plt.show()\n",
    "def Hamilton0(distance, n_rings, n_chains):\n",
    "    N_atoms = n_chains * n_rings\n",
    "    Pos = cyl_positions(distance, N_atoms, n_chains) # sample_positions(mean_pos, sigma_pos, N_atoms)        #\n",
    "    atom_frequencies = sample_frequencies(omega_a, 0.0125 * omega_a, N_atoms) # [omega_a] * N_atoms #\n",
    "    H = 0\n",
    "    for a in range(N_atoms):\n",
    "        for b in range(N_atoms):\n",
    "            op = sm_list[a].dag() * sm_list[b]\n",
    "            if a != b:\n",
    "                ra, rb = Pos[a, :], Pos[b, :]\n",
    "                H += alpha / (np.linalg.norm(rb-ra))**3 * op\n",
    "            else:\n",
    "                H += atom_frequencies[a] *op # Diagonals except for |0><0|\n",
    "    return H\n",
    "def El_field(t, args):\n",
    "    t0 = args['time']\n",
    "    Delta = args['Delta']\n",
    "    E = np.exp(1j*(args['omega'] * t + args['phi']))\n",
    "    E += np.conjugate(E)\n",
    "    # secure the field is 0 outside short range\n",
    "    E *= np.cos(np.pi * (t - t0) / (2 * Delta)) ** 2 * np.heaviside(t - (t0 - Delta), 0) * np.heaviside(t0 + Delta - t,0)\n",
    "    return args['E0'] * E\n",
    "\n",
    "# Define the ground & the excited states\n",
    "# atomic dofs\n",
    "atom_g = basis(N_atoms + 1, 0)\n",
    "atom_es = [basis(N_atoms + 1, i) for i in range(1, N_atoms + 1)]\n",
    "# initial state\n",
    "psiini = atom_g # = |g>_atom\n",
    "\n",
    "# combined dofs\n",
    "sm_list = []    # lowering operators of atomic system\n",
    "Dip_op = 0         # collective sigma_x operator for the system\n",
    "for i in range(N_atoms):\n",
    "    op = atom_g * atom_es[i].dag()\n",
    "    sm_list.append(op)\n",
    "    Dip_op += mu * op + mu * op.dag()\n",
    "H0 = Hamilton0(distance, n_rings, n_chains)\n",
    "\n",
    "# Jump / Expect Operators          # Define the decay collapse and dephasing operator for each spin\n",
    "# Collapse operators\n",
    "c_op2 = [np.sqrt(gamma_0) * op for op in sm_list]                         # Individual atom decays\n",
    "c_op4 = [np.sqrt(gamma_phi) * commutator(op.dag(), op) for op in sm_list] # Individual atom dephasing\n",
    "c_op_list = c_op2 + c_op4  # Combine all collapse operators\n",
    "# Expectation operators for measuring populations across atomic ground and excited levels\n",
    "e_op_list = [ket2dm(basis(N_atoms + 1, i)) for i in range(N_atoms + 1)]\n",
    "\n",
    "#\n",
    "# evolution with t\n",
    "#\n",
    "# create the time dependant evolution\n",
    "Omegas = [omega_R, omega_R, omega_R/10] # Probe pulse is smaller\n",
    "omegas = [omega_a, omega_a, omega_a]    # The laser is on resonant\n",
    "Delta_ts = [t_max*1e-3, t_max*1e-3, t_max*1e-3] # narrow width of the pulses\n",
    "HI = [-Dip_op, El_field] # interaction Hamiltonian with function-based time dependence\n",
    "H = [H0, HI]\n",
    "options = Options(store_states=True)\n",
    "\n",
    "\n",
    "#\n",
    "# PREPROCESSING\n",
    "#\n",
    "# Phase cycling\n",
    "phases = [-1 * i * np.pi / 2 for i in range(4)]"
   ],
   "id": "76bb23c3f08969f5",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T15:45:39.092344Z",
     "start_time": "2025-02-04T15:45:39.086089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_times_for_T(T, steps=medium_steps):\n",
    "    \"\"\"\n",
    "    Generate medium-sparse time arrays for a given T.\n",
    "\n",
    "    Parameters:\n",
    "        T (float): The value of T.\n",
    "        t_max (float): Maximum time value.\n",
    "        steps (int): Number of steps for medium resolution.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Arrays (times_t, times_tau)\n",
    "            times_t (ndarray): Array from T to t_max with medium resolution.\n",
    "            times_tau (ndarray): Array from 0 to T with medium resolution.\n",
    "    \"\"\"\n",
    "    times_t = np.linspace(0, t_max - T - 2 * Delta_ts[2], steps)\n",
    "    times_tau = np.linspace(0, t_max - T - 2 * Delta_ts[0], steps)\n",
    "    return times_t, times_tau\n",
    "\n",
    "def process_close_times(fine_times, times_tau, tolerance=1e-2):\n",
    "    \"\"\"\n",
    "    Processes fine times and returns indices of fine_times when a time is close to a value in times_tau.\n",
    "    Ensures each tau is handled only once.\n",
    "\n",
    "    Parameters:\n",
    "        fine_times (list or array): High-resolution time values.\n",
    "        times_tau (list or array): Target time values to match against.\n",
    "        tolerance (float): Maximum allowed difference to consider two times \"close.\"\n",
    "\n",
    "    Returns:\n",
    "        List[int]: Indices of fine_times where the times are close to values in times_tau.\n",
    "    \"\"\"\n",
    "    # Keep track of already processed tau values\n",
    "    processed_taus = set()\n",
    "    close_indices = []\n",
    "\n",
    "    # Iterate over the fine times array\n",
    "    for i, time in enumerate(fine_times):\n",
    "        # Check for close times_tau values\n",
    "        for tau in times_tau:\n",
    "            if tau not in processed_taus and abs(time - tau) <= tolerance:\n",
    "                # Add the index to the list of close indices\n",
    "                close_indices.append(i)\n",
    "\n",
    "                # Mark this tau as processed to avoid duplicates\n",
    "                processed_taus.add(tau)\n",
    "\n",
    "    return close_indices\n",
    "\n",
    "times_t_test, times_tau_test = get_times_for_T(0)\n",
    "len(times), len(times_t_test), len(times_tau_test), len(times_T)\n",
    "#close_times_indices = process_close_times(times, times_tau_test)\n",
    "#print(close_times_indices, times_tau_test, times[close_times_indices])"
   ],
   "id": "4a4ce3160a576aed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T15:45:43.076292Z",
     "start_time": "2025-02-04T15:45:40.020917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# CALCULATIONS\n",
    "#\n",
    "def compute_pulse(psiini, times, phi, i):\n",
    "    args = {\n",
    "        'phi': phi,\n",
    "        'time': Delta_ts[i],\n",
    "        'omega': omegas[i],\n",
    "        'Delta': Delta_ts[i],\n",
    "        'E0': Omegas[i]\n",
    "    }\n",
    "    result = mesolve(H, psiini, times, c_ops=c_op_list, e_ops=e_op_list, args=args, options=options)\n",
    "    return result.states\n",
    "def compute_two_dimensional_polarization(T_val, phi_1, phi_2):\n",
    "    times_0 = times\n",
    "    t_values, tau_values = get_times_for_T(T_val)\n",
    "    data = np.zeros((len(tau_values), len(t_values))) # x -> t, y -> tau\n",
    "    close_times_tau = process_close_times(times_0 - Delta_ts[0], tau_values)\n",
    "\n",
    "    data_1 = compute_pulse(psiini, times_0, phi_1, 0) # first pulse\n",
    "\n",
    "    for tau_idx, tau in enumerate(tau_values):\n",
    "        i = np.abs(tau_values[tau_idx] - (times_0 + Delta_ts[1] - Delta_ts[0])).argmin()  # find the index where T_val is\n",
    "        psi_1 = data_1[i]  # Access psi_2 after waiting T\n",
    "\n",
    "        times_1 = times[i:] - times[i]\n",
    "\n",
    "        data_2 = compute_pulse(psi_1, times_1, phi_2, 1) # second pulse\n",
    "\n",
    "        j = np.abs(times_1 + Delta_ts[2] - Delta_ts[1] - T_val).argmin()  # find the index where T_val is\n",
    "\n",
    "        T_curr = times_1[j] + Delta_ts[2] - Delta_ts[1]  # current time val\n",
    "\n",
    "        psi_2 = data_2[j]  # Access psi_2 after waiting T\n",
    "        times_2 = times[j:] - times[j]\n",
    "\n",
    "        close_times_t = process_close_times(times_2 - Delta_ts[2], t_values)\n",
    "\n",
    "        data_f = compute_pulse(psi_2, times_2, 0, 2) # third pulse\n",
    "\n",
    "        for t_idx, t in enumerate(t_values):\n",
    "            k = np.abs(t_values[t_idx] - times_2 - Delta_ts[2]).argmin()  # find the closest index\n",
    "            psi_f = data_f[k]  # Access psi_2 after waiting T\n",
    "            # Compute the polarization and store it in the dictionary\n",
    "            Polarization = expect(Dip_op, psi_f)\n",
    "            data[tau_idx, t_idx] = Polarization\n",
    "\n",
    "    # Crop non-zero data\n",
    "    non_zero_rows = np.any(data != 0, axis=1)\n",
    "    non_zero_cols = np.any(data != 0, axis=0)\n",
    "    data = data[non_zero_rows][:, non_zero_cols]\n",
    "    tau_values = tau_values[non_zero_rows]\n",
    "    t_values = t_values[non_zero_cols]\n",
    "\n",
    "    return tau_values, t_values, data\n",
    "def process_phi_combination(phi_1, phi_2):\n",
    "    dict_T = {}\n",
    "    for T in times_T:\n",
    "        tau_values, t_values, data = compute_two_dimensional_polarization(T, phi_1, phi_2)\n",
    "        dict_T[T] = tau_values, t_values, data\n",
    "    return dict_T\n",
    "x = compute_two_dimensional_polarization(3, 0, 0)\n",
    "plot_positive_color_map(x[1], x[0], x[2], safe=False)"
   ],
   "id": "47e400ddb6edf4b",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 62\u001B[0m\n\u001B[1;32m     60\u001B[0m         dict_T[T] \u001B[38;5;241m=\u001B[39m tau_values, t_values, data\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dict_T\n\u001B[0;32m---> 62\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_two_dimensional_polarization\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m plot_positive_color_map(x[\u001B[38;5;241m1\u001B[39m], x[\u001B[38;5;241m0\u001B[39m], x[\u001B[38;5;241m2\u001B[39m], safe\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[19], line 37\u001B[0m, in \u001B[0;36mcompute_two_dimensional_polarization\u001B[0;34m(T_val, phi_1, phi_2)\u001B[0m\n\u001B[1;32m     34\u001B[0m psi_2 \u001B[38;5;241m=\u001B[39m data_2[j]  \u001B[38;5;66;03m# Access psi_2 after waiting T\u001B[39;00m\n\u001B[1;32m     35\u001B[0m times_2 \u001B[38;5;241m=\u001B[39m times[j:] \u001B[38;5;241m-\u001B[39m times[j]\n\u001B[0;32m---> 37\u001B[0m close_times_t \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_close_times\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimes_2\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mDelta_ts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_values\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m data_f \u001B[38;5;241m=\u001B[39m compute_pulse(psi_2, times_2, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m) \u001B[38;5;66;03m# third pulse\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t_idx, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(t_values):\n",
      "Cell \u001B[0;32mIn[18], line 40\u001B[0m, in \u001B[0;36mprocess_close_times\u001B[0;34m(fine_times, times_tau, tolerance)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, time \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(fine_times):\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;66;03m# Check for close times_tau values\u001B[39;00m\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tau \u001B[38;5;129;01min\u001B[39;00m times_tau:\n\u001B[0;32m---> 40\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m tau \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_taus \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mabs\u001B[39m(time \u001B[38;5;241m-\u001B[39m tau) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m tolerance:\n\u001B[1;32m     41\u001B[0m             \u001B[38;5;66;03m# Add the index to the list of close indices\u001B[39;00m\n\u001B[1;32m     42\u001B[0m             close_indices\u001B[38;5;241m.\u001B[39mappend(i)\n\u001B[1;32m     44\u001B[0m             \u001B[38;5;66;03m# Mark this tau as processed to avoid duplicates\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T15:47:35.225446Z",
     "start_time": "2025-02-04T15:45:45.634946Z"
    }
   },
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Initialize results dictionary\n",
    "all_results = {}\n",
    "# Parallelize the computation for all combinations of phi_1 and phi_2\n",
    "max_workers = min(len(phases) ** 2, os.cpu_count())  # Limit workers based on available CPUs\n",
    "with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Track each future and corresponding (phi_1, phi_2)\n",
    "    futures = {executor.submit(process_phi_combination, phi_1, phi_2): (phi_1, phi_2)\n",
    "               for phi_1 in phases for phi_2 in phases}\n",
    "\n",
    "    # Collect results as they complete\n",
    "    for future in futures:\n",
    "        phi_1, phi_2 = futures[future]  # Retrieve the associated (phi_1, phi_2)\n",
    "        third_pulse_data = future.result()\n",
    "        if third_pulse_data is not None:\n",
    "            all_results[(phi_1, phi_2)] = third_pulse_data\n",
    "\n",
    "#all_results[(0,0)] # now contains the results keyed by (phi_1, phi_2)"
   ],
   "id": "d60dd90324acfdca",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T16:28:33.793864Z",
     "start_time": "2025-02-04T16:28:33.785087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for T_j, (taus, ts, data_time) in T_averaged_dict.items():  # Use enumerate to count iterations\n",
    "    if T_j == 0:  # First iteration\n",
    "        global_ts = ts\n",
    "        global_taus = taus\n",
    "        global_t_freqs = (np.fft.fftfreq(len(global_ts), d=(global_ts[1] - global_ts[0])))  # Frequency axis for detection time\n",
    "        global_tau_freqs = (np.fft.fftfreq(len(global_taus), d=(global_taus[1] - global_taus[0])))  # Frequency axis for excitation time\n",
    "\n",
    "        # Sum all data into global sum\n",
    "        global_data_time = np.zeros((len(global_taus), len(global_ts)))\n",
    "        global_data_freq = np.zeros((len(global_taus), len(global_ts)), dtype=np.complex64)\n",
    "\n",
    "\n",
    "    if len(taus) < 4 or len(ts) < 4:\n",
    "        print(f\"Skipped T_j={T_j} due to insufficient data (taus={len(taus)}, ts={len(ts)})\")\n",
    "        continue\n",
    "\n",
    "    # Prepare to extend local data into global coordinates\n",
    "    data_extended_time = np.zeros_like(global_data_time)\n",
    "\n",
    "    # Map taus and ts to global indices\n",
    "    global_tau_indices = {tau: idx for idx, tau in enumerate(global_taus)}\n",
    "    global_t_indices = {t: idx for idx, t in enumerate(global_ts)}\n",
    "\n",
    "    # Map taus and ts to global indices\n",
    "    for i, tau in enumerate(taus):\n",
    "        global_i = np.where(global_taus == tau)[0]  # Array of indices where condition is True\n",
    "        if global_i.size > 0:  # Ensure we have valid matches\n",
    "            global_i = global_i[0]\n",
    "        else:\n",
    "            continue  # Skip if no valid mapping\n",
    "\n",
    "        for j, t in enumerate(ts):\n",
    "            global_j = np.where(global_ts == t)[0]  # Array of indices where condition is True\n",
    "            if global_j.size > 0:  # Ensure we have valid matches\n",
    "                global_j = global_j[0]\n",
    "            else:\n",
    "                continue  # Skip if no valid mapping\n",
    "\n",
    "            # Assign values if valid global indices exist\n",
    "            data_extended_time[global_i, global_j] = data_time[i, j]\n",
    "            global_data_time[global_i, global_j] += data_time[i, j]\n",
    "\n",
    "    data_extended_freq = np.fft.fft2(data_extended_time)\n",
    "    plot_positive_color_map(ts, taus, data_time, T_j)\n",
    "    plot_positive_color_map(np.fft.fftfreq(len(ts), d=(ts[1] - ts[0])), np.fft.fftfreq(len(taus), d=(taus[1] - taus[0])), np.fft.fft2(data_time), T_j, space = \"freq\", type = \"real\", positive = True, safe = False)\n",
    "\n",
    "#    plot_positive_color_map(global_ts, global_taus, data_extended_time, T_j, safe = False)\n",
    "#    plot_positive_color_map(global_t_freqs, global_tau_freqs, data_extended_freq, T_j, space = \"freq\", type = \"real\", positive = True, safe = False)\n",
    "    global_data_freq += data_extended_freq\n",
    "\n",
    "# Plot the aggregated results\n",
    "#plot_positive_color_map(global_ts, global_taus, global_data_time, safe=False)  # Global time-space data\n",
    "#plot_positive_color_map(global_t_freqs, global_tau_freqs, (global_data_freq), space=\"freq\", type=\"real\", positive=True, safe=False)  # Global frequency-space data"
   ],
   "id": "62aee5819a3a1068",
   "outputs": [],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
