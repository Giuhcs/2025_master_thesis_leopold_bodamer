{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "516ac34f",
            "metadata": {},
            "source": [
                "# Replicate Paper Results: 1D and 2D Spectroscopy Data Processing\n",
                "\n",
                "This notebook loads and plots both 1D and 2D spectroscopy data from pickle files to replicate paper results."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5bbc77f1",
            "metadata": {},
            "source": [
                "# Generalized Functions for Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "5d663820",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üñ•Ô∏è  Forcing Agg backend to simulate headless HPC environment\n"
                    ]
                }
            ],
            "source": [
                "# =============================\n",
                "# IMPORTS\n",
                "# =============================\n",
                "import os\n",
                "import sys\n",
                "import gzip\n",
                "import pickle\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "### Project-specific imports\n",
                "from config.paths import DATA_DIR, FIGURES_DIR\n",
                "from qspectro2d.spectroscopy.post_processing import extend_and_plot_results\n",
                "from qspectro2d.visualization.plotting import plot_2d_el_field, plot_fixed_tau_t\n",
                "from config import mpl_tex_settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94dc089f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================\n",
                "# GENERALIZED DATA LOADING FUNCTIONS\n",
                "# =============================\n",
                "\n",
                "def find_latest_file(data_subdir: str, file_pattern: str = \"*.pkl\") -> Path:\n",
                "    \"\"\"Find the most recent file matching pattern in a data subdirectory.\n",
                "    \n",
                "    Args:\n",
                "        data_subdir: Subdirectory within DATA_DIR (e.g., '1d_spectroscopy', 'raw/2d_spectroscopy')\n",
                "        file_pattern: Glob pattern for file matching\n",
                "    \n",
                "    Returns:\n",
                "        Path to the latest file or None if not found\n",
                "    \"\"\"\n",
                "    data_dir = DATA_DIR / data_subdir\n",
                "    \n",
                "    if not data_dir.exists():\n",
                "        print(f\"‚ùå Data directory does not exist: {data_dir}\")\n",
                "        return None\n",
                "    \n",
                "    # Look for files matching the pattern\n",
                "    files = list(data_dir.glob(file_pattern))\n",
                "    \n",
                "    # For 2D data, also look for compressed files\n",
                "    if \"2d_spectroscopy\" in data_subdir:\n",
                "        files.extend(list(data_dir.glob(\"*.pkl.gz\")))\n",
                "    \n",
                "    if not files:\n",
                "        print(f\"‚ùå No files matching '{file_pattern}' found in {data_dir}\")\n",
                "        return None\n",
                "    \n",
                "    # Get the most recent file\n",
                "    latest_file = max(files, key=lambda p: p.stat().st_mtime)\n",
                "    print(f\"‚úÖ Found latest file: {latest_file.name}\")\n",
                "    return latest_file\n",
                "\n",
                "\n",
                "def load_pickle_file(filepath: Path) -> dict:\n",
                "    \"\"\"Load data from pickle file (supports both .pkl and .pkl.gz).\n",
                "    \n",
                "    Args:\n",
                "        filepath: Path to the pickle file\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary containing the loaded data or None if error\n",
                "    \"\"\"\n",
                "    print(f\"Loading data from: {filepath.name}\")\n",
                "    \n",
                "    try:\n",
                "        if filepath.suffix == \".gz\":\n",
                "            # Handle compressed pickle files\n",
                "            with gzip.open(filepath, \"rb\") as f:\n",
                "                data = pickle.load(f)\n",
                "        else:\n",
                "            # Handle regular pickle files\n",
                "            with open(filepath, \"rb\") as f:\n",
                "                data = pickle.load(f)\n",
                "        \n",
                "        print(f\"‚úÖ Data loaded successfully!\")\n",
                "        return data\n",
                "    \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error loading file: {e}\")\n",
                "        return None\n",
                "\n",
                "\n",
                "def create_output_directory(subdir: str) -> Path:\n",
                "    \"\"\"Create output directory for figures.\n",
                "    \n",
                "    Args:\n",
                "        subdir: Subdirectory name within FIGURES_DIR\n",
                "    \n",
                "    Returns:\n",
                "        Path to the created output directory\n",
                "    \"\"\"\n",
                "    output_dir = FIGURES_DIR / subdir\n",
                "    os.makedirs(output_dir, exist_ok=True)\n",
                "    return output_dir\n",
                "\n",
                "\n",
                "from typing import Dict, Any\n",
                "def average_data_1d(data_dir: str, file_pattern: str = \"*.pkl\", output_filename: str = \"averaged_data.pkl\") -> Dict[str, Any]:\n",
                "    \"\"\"Average data from multiple pickle files in a directory.\n",
                "    \n",
                "    Args:\n",
                "        data_dir: Directory containing pickle files to process\n",
                "        file_pattern: Pattern to match files (e.g., \"*.pkl\", \"1d_data_*.pkl\")\n",
                "        output_filename: Name of the output file to save averaged data\n",
                "        \n",
                "    Returns:\n",
                "        Dictionary containing the averaged data\n",
                "    \"\"\"\n",
                "    # Convert to Path object for consistency\n",
                "    data_path = Path(data_dir)\n",
                "    \n",
                "    # Get all matching pickle files in the directory\n",
                "    pkl_files = list(data_path.glob(file_pattern))\n",
                "    \n",
                "    # Also look for compressed files if applicable\n",
                "    if \"pkl\" in file_pattern:\n",
                "        compressed_pattern = file_pattern.replace(\".pkl\", \".pkl.gz\")\n",
                "        pkl_files.extend(list(data_path.glob(compressed_pattern)))\n",
                "    \n",
                "    if not pkl_files:\n",
                "        print(f\"‚ùå No files matching '{file_pattern}' found in {data_dir}\")\n",
                "        return None\n",
                "    \n",
                "    pkl_files.sort()  # Sort for consistent processing\n",
                "    print(f\"Found {len(pkl_files)} pickle files to average.\")\n",
                "    \n",
                "    # Initialize variables to store accumulated data\n",
                "    sum_data_avg = None\n",
                "    total_n_freqs = 0\n",
                "    first_file_data = None\n",
                "    \n",
                "    # Process each file and accumulate data\n",
                "    for i, file_path in enumerate(pkl_files):\n",
                "        # Use the existing load_pickle_file function\n",
                "        loaded_data = load_pickle_file(file_path)\n",
                "        \n",
                "        if loaded_data is not None:\n",
                "            # Store data from the first file to use as template\n",
                "            if i == 0:\n",
                "                first_file_data = loaded_data\n",
                "                # Initialize sum_data_avg with the right shape\n",
                "                sum_data_avg = loaded_data['data_avg'].copy()\n",
                "            else:\n",
                "                # Add data_avg from current file\n",
                "                sum_data_avg += loaded_data['data_avg']\n",
                "            \n",
                "            # Accumulate n_freqs\n",
                "            total_n_freqs += loaded_data['n_freqs']\n",
                "            \n",
                "            print(f\"‚úÖ Processed file {i+1}/{len(pkl_files)}\")\n",
                "        else:\n",
                "            print(f\"‚ùå Skipping file due to load error: {file_path.name}\")\n",
                "    \n",
                "    # Check if we have valid data to average\n",
                "    if first_file_data is None or sum_data_avg is None:\n",
                "        print(\"‚ùå No valid data files were processed.\")\n",
                "        return None\n",
                "        \n",
                "    # Count successfully processed files (might be less than total if some failed)\n",
                "    processed_count = sum(1 for f in pkl_files if load_pickle_file(f) is not None)\n",
                "    \n",
                "    if processed_count == 0:\n",
                "        print(\"‚ùå No files were successfully processed.\")\n",
                "        return None\n",
                "    \n",
                "    # Create averaged data dictionary\n",
                "    averaged_data = {\n",
                "        't_det_vals': first_file_data['t_det_vals'],\n",
                "        'data_avg': sum_data_avg / processed_count,  # Average the accumulated data\n",
                "        'tau_coh': first_file_data['tau_coh'],\n",
                "        'T_wait': first_file_data['T_wait'],\n",
                "        'system': first_file_data['system'],\n",
                "        'n_freqs': total_n_freqs\n",
                "    }\n",
                "    \n",
                "    # Save averaged data to output file\n",
                "    output_path = data_path / output_filename\n",
                "    with open(output_path, 'wb') as f:\n",
                "        pickle.dump(averaged_data, f)\n",
                "    \n",
                "    print(f\"‚úÖ Averaged data saved to: {output_path}\")\n",
                "    print(f\"  - Averaged across {processed_count} files\")\n",
                "    print(f\"  - Total frequencies: {total_n_freqs}\")\n",
                "    \n",
                "    return averaged_data\n",
                "\n",
                "def average_data_2d(data_dir: str, file_pattern: str = \"*d.pkl\", output_filename: str = \"averaged_2d_data.pkl\") -> Dict[str, Any]:\n",
                "    \"\"\"Average 2D spectroscopy data from multiple pickle files in a directory.\n",
                "    \n",
                "    Args:\n",
                "        data_dir: Directory containing pickle files to process\n",
                "        file_pattern: Pattern to match files (e.g., \"*d.pkl\", \"2d_data_*.pkl\")\n",
                "        output_filename: Name of the output file to save averaged data\n",
                "        \n",
                "    Returns:\n",
                "        Dictionary containing the averaged data\n",
                "    \"\"\"\n",
                "    # Convert to Path object for consistency\n",
                "    data_path = Path(data_dir)\n",
                "    \n",
                "    # Get all matching pickle files in the directory\n",
                "    pkl_files = list(data_path.glob(file_pattern))\n",
                "    \n",
                "    # Also look for compressed files if applicable\n",
                "    if \"pkl\" in file_pattern:\n",
                "        compressed_pattern = file_pattern.replace(\".pkl\", \".pkl.gz\")\n",
                "        pkl_files.extend(list(data_path.glob(compressed_pattern)))\n",
                "    \n",
                "    if not pkl_files:\n",
                "        print(f\"‚ùå No files matching '{file_pattern}' found in {data_dir}\")\n",
                "        return None\n",
                "    \n",
                "    pkl_files.sort()  # Sort for consistent processing\n",
                "    print(f\"Found {len(pkl_files)} pickle files to average.\")\n",
                "    \n",
                "    # Initialize variables to store accumulated data\n",
                "    sum_two_d_datas = None\n",
                "    total_n_freqs = 0\n",
                "    first_file_data = None\n",
                "    processed_count = 0\n",
                "    \n",
                "    # Process each file and accumulate data\n",
                "    for i, file_path in enumerate(pkl_files):\n",
                "        # Use the existing load_pickle_file function\n",
                "        loaded_data = load_pickle_file(file_path)\n",
                "        \n",
                "        if loaded_data is not None:\n",
                "            # Store data from the first file to use as template\n",
                "            if i == 0:\n",
                "                first_file_data = loaded_data\n",
                "                # Initialize sum_two_d_datas with the right shape AND dtype\n",
                "                # For 2D data: two_d_datas is a list of arrays, one for each T_wait time\n",
                "                # Use astype(complex) to ensure we preserve complex values\n",
                "                sum_two_d_datas = [arr.copy().astype(complex) for arr in loaded_data['two_d_datas']]\n",
                "            else:\n",
                "                # Add corresponding 2D arrays for each T_wait time\n",
                "                for j, arr in enumerate(loaded_data['two_d_datas']):\n",
                "                    sum_two_d_datas[j] += arr.astype(complex)\n",
                "            \n",
                "            # Accumulate n_freqs\n",
                "            total_n_freqs += loaded_data['n_freqs']\n",
                "            processed_count += 1\n",
                "            \n",
                "            print(f\"‚úÖ Processed file {i+1}/{len(pkl_files)}: {file_path.name}\")\n",
                "        else:\n",
                "            print(f\"‚ùå Skipping file due to load error: {file_path.name}\")\n",
                "    \n",
                "    # Check if we have valid data to average\n",
                "    if first_file_data is None or sum_two_d_datas is None:\n",
                "        print(\"‚ùå No valid data files were processed.\")\n",
                "        return None\n",
                "        \n",
                "    if processed_count == 0:\n",
                "        print(\"‚ùå No files were successfully processed.\")\n",
                "        return None\n",
                "    \n",
                "    # Create averaged data dictionary\n",
                "    averaged_data = {\n",
                "        'times': first_file_data['times'],\n",
                "        'times_T': first_file_data['times_T'],\n",
                "        'system': first_file_data['system'],\n",
                "        # Calculate average for each 2D array in the list\n",
                "        'two_d_datas': [arr / processed_count for arr in sum_two_d_datas],\n",
                "        'n_times_T': first_file_data['n_times_T'],\n",
                "        'n_phases': first_file_data['n_phases'],\n",
                "        'n_freqs': total_n_freqs  # Sum of all n_freqs values\n",
                "    }\n",
                "    \n",
                "    # Save averaged data to output file\n",
                "    output_path = data_path / output_filename\n",
                "    with open(output_path, 'wb') as f:\n",
                "        pickle.dump(averaged_data, f)\n",
                "    \n",
                "    print(f\"‚úÖ Averaged 2D data saved to: {output_path}\")\n",
                "    print(f\"  - Averaged across {processed_count} files\")\n",
                "    print(f\"  - Total frequencies: {total_n_freqs}\")\n",
                "    print(f\"  - Number of T wait times: {len(averaged_data['two_d_datas'])}\")\n",
                "    print(f\"  - Shape of each 2D array: {averaged_data['two_d_datas'][0].shape}\")\n",
                "    \n",
                "    return averaged_data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a9cd858a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================\n",
                "# AVERAGE SIMULATION DATA FROM MULTIPLE PICKLE FILES\n",
                "# =============================\n",
                "\n",
                "# Example usage:\n",
                "# Set data_dir to the directory containing pickle files to average\n",
                "# Use pathlib for path operations\n",
                "data_dir = DATA_DIR / \"1d_spectroscopy\" / \"inhomogeneity\"\n",
                "averaged_data = average_data_1d(\n",
                "    data_dir,\n",
                "    file_pattern=\"1d_data_*.pkl\",  # Optional: specify pattern to match specific files\n",
                "    output_filename=\"1d_data_averaged.pkl\"\n",
                ")\n",
                "\n",
                "# You can then use the averaged data for plotting or further analysis\n",
                "# For example:\n",
                "if averaged_data is not None:\n",
                "    plot_fixed_tau_t(\n",
                "        averaged_data['t_det_vals'], \n",
                "        averaged_data['data_avg'],\n",
                "        tau_coh=averaged_data['tau_coh'],\n",
                "        T_wait=averaged_data['T_wait'],\n",
                "        n_freqs=averaged_data['n_freqs']\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d1fd510",
            "metadata": {},
            "source": [
                "# 1. Process 1D Spectroscopy Data (Fixed œÑ, T)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bf671d31",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================\n",
                "# LOAD AND PLOT 1D SPECTROSCOPY DATA\n",
                "# =============================\n",
                "\n",
                "### Find and load 1D data\n",
                "file_path_1d = find_latest_file(\"1d_spectroscopy/inhomogeneity\", \"1d_data_*.pkl\")\n",
                "\n",
                "if file_path_1d is not None:\n",
                "    loaded_data = load_pickle_file(file_path_1d)\n",
                "    \n",
                "    if loaded_data is not None:\n",
                "        # Extract 1D data\n",
                "        t_det_vals = loaded_data['t_det_vals']\n",
                "        data_avg   = loaded_data['data_avg']\n",
                "        tau_coh    = loaded_data['tau_coh']\n",
                "        T_wait     = loaded_data['T_wait']\n",
                "        system     = loaded_data['system']\n",
                "        n_freqs  = loaded_data['n_freqs']\n",
                "        \n",
                "        ### Display data information\n",
                "        print(f\"  œÑ_coh = {tau_coh:.2f} fs\")\n",
                "        print(f\"  T_wait = {T_wait:.2f} fs\")\n",
                "        print(f\"  t_det_vals: {len(t_det_vals)} points from {t_det_vals[0]:.2f} to {t_det_vals[-1]:.2f} fs\")\n",
                "        print(f\"  data_avg shape: {data_avg.shape}\")\n",
                "        print(f\"  œâ_ats: {n_freqs} frequencies\")\n",
                "        print(f\"  System parameters: {system}\")\n",
                "        \n",
                "        ### Prepare plotting arguments\n",
                "        output_dir = create_output_directory(\"1d_spectroscopy/inhomogeneity\")\n",
                "        kwargs = {\n",
                "            'tau_coh': tau_coh,\n",
                "            'T_wait': T_wait,\n",
                "            'n_freqs': n_freqs,\n",
                "            'envelope': system.pulse_type,\n",
                "            'RWA': system.RWA_SL,\n",
                "            'Solver': system.ODE_Solver,\n",
                "            'function': \"E_{k_s}\", # ONLY IF THE DATA comes from \"parallel_compute_1d_E_with_inhomogeneity\",\n",
                "            'show': False  # Don't show the plot yet, we'll save it first\n",
                "        }\n",
                "        \n",
                "        ### Generate 1D plot\n",
                "        print(\"üìä Generating 1D spectroscopy plot...\")\n",
                "        # Plot and get the figure object\n",
                "        fig = plot_fixed_tau_t(t_det_vals, data_avg, **kwargs)\n",
                "\n",
                "        # Save the figure with a descriptive filename\n",
                "        output_path = output_dir / f\"1d_spectroscopy_{file_path_1d.stem}.png\"\n",
                "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
                "        print(f\"‚úÖ 1D plot saved to: {output_path}\")\n",
                "        \n",
                "        # Now display the plot\n",
                "        plt.show()\n",
                "        \n",
                "    else:\n",
                "        print(\"‚ùå Failed to load 1D spectroscopy data.\")\n",
                "else:\n",
                "    print(\"   Please run the 1D spectroscopy calculation first to generate data.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4eb89ea2",
            "metadata": {},
            "source": [
                "# 2. Process 2D Spectroscopy Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "32830608",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================\n",
                "# AVERAGE SIMULATION DATA FROM MULTIPLE PICKLE FILES\n",
                "# =============================\n",
                "\n",
                "# Example usage:\n",
                "# Set data_dir to the directory containing pickle files to average\n",
                "# Use pathlib for path operations\n",
                "data_dir = DATA_DIR / \"2d_spectroscopy\" / \"new_echo_signal\" / \"900fs\"\n",
                "averaged_data = average_data_2d(\n",
                "    data_dir,\n",
                "    file_pattern=\"2d_data_*.pkl\",  # Optional: specify pattern to match specific files\n",
                "    output_filename=\"2d_data_averaged.pkl\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9baac994",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================\n",
                "# LOAD AND PLOT 2D SPECTROSCOPY DATA\n",
                "# =============================\n",
                "\n",
                "### Find and load 2D data\n",
                "file_path_2d = find_latest_file(\"2d_spectroscopy/new_echo_signal/600fs/\", \"*.pkl\")\n",
                "\n",
                "if file_path_2d is not None:\n",
                "    loaded_data = load_pickle_file(file_path_2d)\n",
                "    \n",
                "    if loaded_data is not None:\n",
                "        # Extract 2D data\n",
                "        two_d_datas = loaded_data[\"two_d_datas\"]\n",
                "        times_T     = loaded_data[\"times_T\"]\n",
                "        times       = loaded_data[\"times\"]\n",
                "        system_data = loaded_data[\"system\"]\n",
                "        \n",
                "        ### Display data information\n",
                "        print(f\"  Loaded {len(two_d_datas)} 2D datasets\")\n",
                "        print(f\"  System data: {system_data}\")\n",
                "        \n",
                "        ### Create output directory\n",
                "        output_dir = create_output_directory(\"2d_spectroscopy/extended\")\n",
                "        \n",
                "        from qspectro2d.spectroscopy.calculations import get_tau_cohs_and_t_dets_for_T_wait\n",
                "        t_det_vals, tau_coh_vals = get_tau_cohs_and_t_dets_for_T_wait(times, times_T[0])\n",
                "        \"\"\"\n",
                "        plot_2d_el_field(\n",
                "            (t_det_vals, tau_coh_vals, two_d_datas[0]),\n",
                "            save=True,  # CHANGE TO False for no plotting the Time domain\n",
                "            output_dir=output_dir,\n",
                "            system=system_data,\n",
                "            use_custom_colormap=True,\n",
                "        )\n",
                "        \"\"\"\n",
                "        ### Plot each component type\n",
                "        spectral_components_to_plot = [\"imag\", \"abs\", \"real\", \"phase\"]\n",
                "        \n",
                "        for component in spectral_components_to_plot:\n",
                "            print(f\"üìä Plotting {component} component...\")\n",
                "            \n",
                "            plot_args = {\n",
                "                \"domain\": \"freq\",\n",
                "                \"type\": component,\n",
                "                \"save\": True,\n",
                "                \"output_dir\": output_dir,\n",
                "                \"use_custom_colormap\": True,\n",
                "                \"section\": (1.5, 1.7, 1.5, 1.7),  # Plot the first section\n",
                "                \"system\": system_data,\n",
                "            }\n",
                "            \n",
                "            try:\n",
                "                extend_and_plot_results(\n",
                "                    two_d_datas,\n",
                "                    times_T=times_T,\n",
                "                    times=times,\n",
                "                    extend_for=(1, 2.3),\n",
                "                    **plot_args,\n",
                "                )\n",
                "                print(f\"‚úÖ {component} plot completed!\")\n",
                "                \n",
                "            except Exception as e:\n",
                "                print(f\"‚ùå Error plotting {component}: {e}\")\n",
                "        \n",
                "        print(f\"üéØ All 2D plots saved to: {output_dir}\")\n",
                "        \n",
                "    else:\n",
                "        print(\"‚ùå Failed to load 2D spectroscopy data.\")\n",
                "else:\n",
                "    print(\"   Please run the 2D spectroscopy calculation first to generate data.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}